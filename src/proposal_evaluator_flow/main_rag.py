# main.py

import os
import asyncio
import json
import glob
import torch
import chromadb
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai.llm import LLM

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

load_dotenv()

# =================================================================
# 1. RAG íŒŒì´í”„ë¼ì¸ ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜
# =================================================================

# --- ê²½ë¡œ ì„¤ì • ---
PROPOSAL_DIR = "./proposal"
RFP_PATH = "./RFP/ìˆ˜í˜‘_rfp.pdf"

# --- ì „ì—­ ë³€ìˆ˜ ---
# ìƒì„±ëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
# Agentë“¤ì´ ê³µìœ í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
unified_vectorstore = None

def initialize_rag_components():
    """RAGì— í•„ìš”í•œ ì„ë² ë”© ëª¨ë¸ê³¼ ChromaDB í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"INFO: RAG ë””ë°”ì´ìŠ¤ë¡œ '{device}'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    print("INFO: ì„ë² ë”© ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤...")
    embedding_model = HuggingFaceEmbeddings(
        model_name="Qwen/Qwen3-Embedding-0.6B",
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    chroma_client = chromadb.PersistentClient(path="./chroma_db_crewai")
    print("INFO: ì„ë² ë”© ëª¨ë¸ ë° ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")
    return embedding_model, chroma_client

def load_document(file_path, doc_type, proposal_name):
    """ë¬¸ì„œ ë¡œë“œ (JSON/PDF/TXT ì§€ì›)"""
    documents = []
    print(f"  - [{doc_type}] '{os.path.basename(file_path)}' ë¡œë”© ì¤‘...")
    
    # ... (RAG ë…¸íŠ¸ë¶ì˜ load_document í•¨ìˆ˜ ë‚´ìš©ê³¼ ë™ì¼) ...
    if file_path.endswith('.pdf'):
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        for doc in docs:
            doc.metadata.update({"doc_type": doc_type, "proposal_name": proposal_name})
        documents.extend(docs)
    elif file_path.endswith('.txt'):
        loader = TextLoader(file_path, encoding='utf-8')
        docs = loader.load()
        for doc in docs:
            doc.metadata.update({"doc_type": doc_type, "proposal_name": proposal_name})
        documents.extend(docs)
    # JSON ë¡œë”ê°€ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì— ì¶”ê°€
    
    print(f"    â†’ {len(documents)}ê°œ ì„¹ì…˜ ë¡œë“œë¨")
    return documents

def create_unified_vectorstore(proposal_files, rfp_path, embedding_model, chroma_client, collection_name="proposal_evaluation_store"):
    """ëª¨ë“  ì œì•ˆì„œì™€ RFP ë¬¸ì„œë¥¼ ë‹¨ì¼ ë²¡í„° ìŠ¤í† ì–´ë¡œ ë³€í™˜"""
    print(f"\n--- [RAG Setup] í†µí•© ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ (Collection: {collection_name}) ---")
    
    all_documents = []
    all_documents.extend(load_document(rfp_path, "RFP", "RFP"))
    for proposal_path in proposal_files:
        proposal_name = os.path.basename(proposal_path)
        all_documents.extend(load_document(proposal_path, "ì œì•ˆì„œ", proposal_name))
        
    print(f"\n  âœ“ ì´ {len(all_documents)}ê°œ ë¬¸ì„œ ì„¹ì…˜ ë¡œë“œ ì™„ë£Œ")

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splits = text_splitter.split_documents(all_documents)
    print(f"  âœ“ {len(splits)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

    try:
        chroma_client.delete_collection(name=collection_name)
        print(f"  âœ“ ê¸°ì¡´ '{collection_name}' ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
    except Exception:
        pass

    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        collection_name=collection_name,
        client=chroma_client
    )
    print("  âœ“ í†µí•© ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
    return vectorstore

def get_context_for_topic(proposal_file, topic):
    """
    (ìˆ˜ì •ëœ í•¨ìˆ˜) ì‹¤ì œ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    global unified_vectorstore
    if unified_vectorstore is None:
        return "ì˜¤ë¥˜: ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    print(f"INFO: RAG ê²€ìƒ‰ ì‹¤í–‰ -> ì œì•ˆì„œ: '{proposal_file}', í† í”½: '{topic}'")
    
    # proposal_file ì´ë¦„ì„ ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰
    results = unified_vectorstore.similarity_search(
        query=topic,
        k=2, # ê´€ë ¨ì„±ì´ ë†’ì€ 2ê°œì˜ ì²­í¬ë¥¼ ê°€ì ¸ì˜´
        filter={"proposal_name": proposal_file}
    )
    
    if not results:
        return "ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    # ê²€ìƒ‰ëœ ê²°ê³¼ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
    context = "\n\n---\n\n".join([doc.page_content for doc in results])
    return context
#==============================================================


# 2. CrewAI Agent ë° í”„ë¡œì„¸ìŠ¤ ì •ì˜
# =================================================================

async def main():
    print("## ë™ì  Agent ìƒì„± ë° í‰ê°€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # --- [ì „ì œ] RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ---
    # ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì „, ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¨¼ì € ì¤€ë¹„í•©ë‹ˆë‹¤.
    global unified_vectorstore
    proposal_files = glob.glob(os.path.join(PROPOSAL_DIR, "*.txt")) # .txt ì œì•ˆì„œë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
    
    if not proposal_files or not os.path.exists(RFP_PATH):
        print("ì˜¤ë¥˜: ì œì•ˆì„œ ë˜ëŠ” RFP íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
        
    embedding_model, chroma_client = initialize_rag_components()
    unified_vectorstore = create_unified_vectorstore(
        proposal_files, RFP_PATH, embedding_model, chroma_client
    )
    # --- RAG ì´ˆê¸°í™” ì™„ë£Œ ---

    # ì „ì²´ ì‹¬ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸
    unstructured_evaluation_items = [
        {"ëŒ€ë¶„ë¥˜": "ê¸°ìˆ ", "topic": "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", "criteria": "MSA ê¸°ë°˜ì˜ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ì¸ê°€?"},
        {"ëŒ€ë¶„ë¥˜": "ê´€ë¦¬", "topic": "í”„ë¡œì íŠ¸ ê´€ë¦¬ ë°©ì•ˆ", "criteria": "WBS ê¸°ë°˜ì˜ ìƒì„¸í•˜ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì¼ì •ì„ ì œì‹œí•˜ì˜€ëŠ”ê°€?"},
        {"ëŒ€ë¶„ë¥˜": "ê¸°ìˆ ", "topic": "ë°ì´í„°ë² ì´ìŠ¤ ì•”í˜¸í™”", "criteria": "ê°œì¸ì •ë³´ë³´í˜¸ ë° ë°ì´í„° ì•”í˜¸í™” ë°©ì•ˆì´ ëª…ì‹œë˜ì—ˆëŠ”ê°€?"},
        {"ëŒ€ë¶„ë¥˜": "ê´€ë¦¬", "topic": "íˆ¬ì… ì¸ë ¥ ê³„íš", "criteria": "íˆ¬ì… ì¸ë ¥ì˜ ì—­í• ê³¼ ê²½ë ¥ì´ ì ì ˆí•œê°€?"},
        {"ëŒ€ë¶„ë¥˜": "ê°€ê²©", "topic": "ë¹„ìš© ì‚°ì • ë‚´ì—­", "criteria": "ì œì‹œëœ ë¹„ìš©ì´ í•©ë¦¬ì ì´ê³  êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ í¬í•¨í•˜ëŠ”ê°€?"},
    ]

    # --- LLM ì •ì˜ ---
    llm = LLM(model="ollama/llama3.2", base_url="http://localhost:11434")

    # =================================================================
    # Phase 1: Dispatcherê°€ ëŒ€ë¶„ë¥˜ë¥¼ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ë‚´ê³  í•­ëª© ë¶„ë¥˜
    # =================================================================
    print("\n--- [Phase 1] Dispatcher Agentê°€ ëŒ€ë¶„ë¥˜ë¥¼ ì‹ë³„í•˜ê³  í•­ëª©ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤ ---")
    
    dispatcher_agent = Agent(
        role="í‰ê°€ í•­ëª© ìë™ ë¶„ë¥˜ ë° ê·¸ë£¹í™” ì „ë¬¸ê°€",
        goal="ì£¼ì–´ì§„ ì‹¬ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸ì—ì„œ 'ëŒ€ë¶„ë¥˜'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  í•­ëª©ì„ ê·¸ë£¹í™”í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜",
        backstory="ë‹¹ì‹ ì€ ë³µì¡í•œ ëª©ë¡ì„ ë°›ì•„ì„œ ì£¼ìš” ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ê³  êµ¬ì¡°í™”í•˜ëŠ” ë° ë§¤ìš° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ê°€ì¡ŒìŠµë‹ˆë‹¤.",
        llm=llm,
        verbose=True
    )

    items_as_string = json.dumps(unstructured_evaluation_items, ensure_ascii=False)
    
    dispatcher_task = Task(
        description=f"""ì•„ë˜ ì‹¬ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ 'ëŒ€ë¶„ë¥˜' í‚¤ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•´ì£¼ì„¸ìš”.
        [ì „ì²´ ì‹¬ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸]: {items_as_string}
        ê²°ê³¼ JSONì˜ keyëŠ” ë¦¬ìŠ¤íŠ¸ì— ì¡´ì¬í•˜ëŠ” 'ëŒ€ë¶„ë¥˜'ì˜ ì´ë¦„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        ê° í•­ëª©ì˜ 'ëŒ€ë¶„ë¥˜', 'topic', 'criteria' í‚¤ì™€ ê°’ì„ ëª¨ë‘ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
        """,
        expected_output="JSON ê°ì²´. ê° keyëŠ” ì‹¬ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸ì— ìˆë˜ 'ëŒ€ë¶„ë¥˜'ì´ë©°, valueëŠ” í•´ë‹¹ ëŒ€ë¶„ë¥˜ì— ì†í•˜ëŠ” í•­ëª© ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê° ê°ì²´ëŠ” ì›ë³¸ì˜ ëª¨ë“  í‚¤-ê°’ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
        agent=dispatcher_agent
    )

    dispatcher_crew = Crew(agents=[dispatcher_agent], tasks=[dispatcher_task], verbose=False)
    categorization_result = dispatcher_crew.kickoff()
    
    try:
        # LLMì´ ìƒì„±í•œ ê²°ê³¼ë¬¼ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_string = categorization_result.raw[categorization_result.raw.find('{'):categorization_result.raw.rfind('}')+1]
        categorized_items = json.loads(json_string)
        print("âœ… í•­ëª© ë¶„ë¥˜ ì™„ë£Œ. ë°œê²¬ëœ ëŒ€ë¶„ë¥˜:")
        for category, items in categorized_items.items():
            print(f"  - {category}: {len(items)}ê°œ í•­ëª©")
    except (json.JSONDecodeError, IndexError):
        print("âŒ í•­ëª© ë¶„ë¥˜ ì‹¤íŒ¨!")
        print(f"   - ì›ë³¸ ê²°ê³¼: {categorization_result.raw}")
        categorized_items = {}

    # =================================================================
    # Phase 2: ëŒ€ë¶„ë¥˜ ê°œìˆ˜ë§Œí¼ ë™ì ìœ¼ë¡œ Agentë¥¼ ìƒì„±í•˜ê³  ë³‘ë ¬ í‰ê°€
    # =================================================================
    print("\n--- [Phase 2] ë°œê²¬ëœ ëŒ€ë¶„ë¥˜ë³„ë¡œ ì „ë¬¸ê°€ Agentë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë³‘ë ¬ í‰ê°€í•©ë‹ˆë‹¤ ---")
    
    # ëª¨ë“  ì œì•ˆì„œ íŒŒì¼ì— ëŒ€í•´ í‰ê°€ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.
    for proposal_path in proposal_files:
        proposal_name = os.path.basename(proposal_path)
        print(f"\n\n{'='*20} [{proposal_name}] í‰ê°€ ì‹œì‘ {'='*20}")

        specialist_agents = []
        evaluation_tasks = []

        for category, items in categorized_items.items():
            specialist_agent = Agent(
                role=f"'{category}' ë¶€ë¬¸ ì „ë¬¸ í‰ê°€ê´€",
                goal=f"'{proposal_name}' ì œì•ˆì„œì˜ '{category}' ë¶€ë¬¸ì„ ì „ë¬¸ì ìœ¼ë¡œ í‰ê°€",
                backstory=f"ë‹¹ì‹ ì€ '{category}' ë¶„ì•¼ ìµœê³ ì˜ ì „ë¬¸ê°€ë¡œì„œ, ì£¼ì–´ì§„ ê´€ë ¨ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì‚¬ ê¸°ì¤€ì— ë”°ë¼ ì œì•ˆì„œë¥¼ ëƒ‰ì² í•˜ê²Œ ë¶„ì„í•˜ê³  í‰ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.",
                llm=llm,
                verbose=True
            )
            specialist_agents.append(specialist_agent)

            for item in items:
                # ìˆ˜ì •ëœ RAG í•¨ìˆ˜ í˜¸ì¶œ
                context = get_context_for_topic(proposal_name, item['topic'])
                
                task = Task(
                    description=f"'{proposal_name}' ì œì•ˆì„œì˜ '{category}' ë¶€ë¬¸ ì¤‘ '{item['topic']}' í•­ëª©ì„ í‰ê°€í•˜ì‹œì˜¤.\n\n- ì‹¬ì‚¬ ê¸°ì¤€: {item['criteria']}\n\n- ì œì•ˆì„œ ê´€ë ¨ ë‚´ìš©:\n---\n{context}\n---\n\nìœ„ ë‚´ìš©ì„ ê·¼ê±°ë¡œ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹œì˜¤.",
                    expected_output=f"'{item['topic']}' í•­ëª©ì— ëŒ€í•œ í‰ê°€ ë³´ê³ ì„œ. ë°˜ë“œì‹œ [í‰ê°€ ì ìˆ˜(1-100)], [í‰ê°€ ìš”ì•½], [íŒë‹¨ ê·¼ê±°] ì„¸ ê°€ì§€ í•­ëª©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
                    agent=specialist_agent
                )
                evaluation_tasks.append(task)
        
        if not evaluation_tasks:
            print("í‰ê°€í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue

        evaluation_crew = Crew(
            agents=specialist_agents,
            tasks=evaluation_tasks,
            verbose=True
        )
        final_results = await evaluation_crew.kickoff_async()

        print(f"\n--- [Phase 3] [{proposal_name}] ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤ ---")
        individual_reports = "\n\n".join([str(result) for result in final_results])

        reporting_agent = Agent(
            role="ìˆ˜ì„ í‰ê°€ ë¶„ì„ê°€",
            goal="ì—¬ëŸ¬ ê°œì˜ ê°œë³„ í‰ê°€ ë³´ê³ ì„œë¥¼ ì¢…í•©í•˜ì—¬, ê²½ì˜ì§„ì´ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ í•˜ë‚˜ì˜ ì™„ì„±ëœ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±",
            backstory="ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë¶€ì„œì˜ ë³´ê³ ë¥¼ ì·¨í•©í•˜ì—¬ í•µì‹¬ë§Œ ìš”ì•½í•˜ê³ , ì „ì²´ì ì¸ ê´€ì ì—ì„œ ê°•ì ê³¼ ì•½ì ì„ ë¶„ì„í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ë° ë§¤ìš° ëŠ¥ìˆ™í•©ë‹ˆë‹¤.",
            llm=llm, verbose=True
        )
        reporting_task = Task(
            description=f"ì•„ë˜ëŠ” '{proposal_name}' ì œì•ˆì„œì— ëŒ€í•œ ê° ë¶„ì•¼ ì „ë¬¸ê°€ë“¤ì˜ ê°œë³„ í‰ê°€ ë³´ê³ ì„œì…ë‹ˆë‹¤.\n\n[ê°œë³„ í‰ê°€ ë³´ê³ ì„œ ëª©ë¡]\n{individual_reports}\n\nìœ„ ë³´ê³ ì„œë“¤ì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬, ì œì•ˆì„œ ì „ì²´ì— ëŒ€í•œ ìµœì¢… í‰ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë³´ê³ ì„œëŠ” [ì´í‰], [ì£¼ìš” ê°•ì ], [ì£¼ìš” ì•½ì ], [ìµœì¢… ì¶”ì²œ ì ìˆ˜(1-100)] í•­ëª©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
            expected_output="í•˜ë‚˜ì˜ ì™„ì„±ëœ ìµœì¢… í‰ê°€ ë³´ê³ ì„œ.",
            agent=reporting_agent
        )
        reporting_crew = Crew(agents=[reporting_agent], tasks=[reporting_task], verbose=False)
        final_comprehensive_report = reporting_crew.kickoff()

        print(f"\n\nğŸš€ [{proposal_name}] ìµœì¢… ì¢…í•© í‰ê°€ ë³´ê³ ì„œ\n==========================================")
        print(final_comprehensive_report.raw)
        print("==========================================\n")


if __name__ == '__main__':
    asyncio.run(main())